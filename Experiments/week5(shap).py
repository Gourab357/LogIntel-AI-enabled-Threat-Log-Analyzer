# -*- coding: utf-8 -*-
"""Week5(SHAP).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tlmAvYGGVz-0iLyMm46LYbZDbUq7m7fg
"""

!pip install shap
!pip install sentence-transformers
!pip install umap-learn
!pip install scikit-learn
!pip install pandas

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import shap
from sentence_transformers import SentenceTransformer

# Load your log data
df = pd.read_csv('/content/drive/MyDrive/LLM4Sec/Week4/BGL_log.csv')

# Clean log messages
import re
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['clean_msg'] = df['Message'].apply(clean_text)

import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
embedder = SentenceTransformer('all-MiniLM-L6-v2', device=device)
embs = embedder.encode(df['clean_msg'].tolist(), show_progress_bar=True, batch_size=64, device=device)

# Add message length and cluster assignment
df['msg_len'] = df['clean_msg'].apply(len)

from sklearn.cluster import MiniBatchKMeans
km = MiniBatchKMeans(n_clusters=4, random_state=42, batch_size=1024)
df['cluster'] = km.fit_predict(embs)

# Combine all features for modeling
features = np.concatenate([
    embs,
    df[['msg_len', 'cluster']].values
], axis=1)

# Feature names
emb_dim = embs.shape[1]
feature_names = [f'emb_{i}' for i in range(emb_dim)] + ['msg_len', 'cluster']

# Define labels for anomaly detection
labels = (df['Alert_Tag'] != '-').astype(int) if 'Alert_Tag' in df.columns else df['cluster']

# Train Random Forest
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(features, labels)

explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(features)
values = shap_values[1] if isinstance(shap_values, list) else shap_values
shap.summary_plot(values, features, feature_names=feature_names, max_display=20)