# -*- coding: utf-8 -*-
"""ELECTRA 2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cDDy9noFCPyJqE2Z2RZu9JD7K_laXpJt
"""

# 1. Install dependencies (Colab)
!pip install transformers datasets torch tqdm --quiet

# 2. Import libraries
import pandas as pd
import numpy as np
import torch
from tqdm import tqdm
from transformers import ElectraTokenizer, ElectraForPreTraining, DataCollatorForLanguageModeling, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.metrics import classification_report, precision_recall_curve, roc_curve, auc
import matplotlib.pyplot as plt

# 3. Data Preparation: Use only 1000 "Normal" logs for ELECTRA training
df = pd.read_csv('/content/drive/MyDrive/LLM4Sec/apache_logs.csv')
df['label'] = df['detected'].map({'BAHAYA': 'Anomalous', 'DICURIGAI': 'Anomalous', 'AMAN': 'Normal'})
df['log'] = df[['ip', 'datetime', 'request', 'status', 'referer', 'browser']].astype(str).agg(' '.join, axis=1)
df = df[['log', 'label']].dropna()

df_normal = df[df['label'] == 'Normal'].sample(n=1000, random_state=42)
logs = df_normal['log'].dropna().tolist()
train_dataset = Dataset.from_dict({"text": logs})

# 4. Tokenizer and model
tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')
def tokenize_function(examples):
    return tokenizer(examples["text"], truncation=True, padding='max_length', max_length=128)
tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=["text"])
collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)
model = ElectraForPreTraining.from_pretrained('google/electra-small-discriminator')

# 5. Training arguments (increase epochs for better learning!)
training_args = TrainingArguments(
    output_dir="./electra-mlm-logs",
    num_train_epochs=3,                  # Trying 3 for improvement
    per_device_train_batch_size=32,
    save_strategy="epoch",
    save_total_limit=2,
    learning_rate=2e-5,
    weight_decay=0.01,
    report_to="none",
    overwrite_output_dir=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized,
    tokenizer=tokenizer,
    data_collator=collator,
)

trainer.train()

# 6. Use your balanced test set (1000 Normal + 1000 Anomalous logs)
df_balanced = pd.read_csv('/content/drive/MyDrive/LLM4Sec/apache_logs_balanced.csv')
test_logs = df_balanced['log'].tolist()
y_true = [1 if l == 'Normal' else 0 for l in df_balanced['label']]

# 7. Batch anomaly scoring with progress bar
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

def compute_anomaly_score_batch(log_lines, batch_size=32):
    model.eval()
    scores = []
    for i in tqdm(range(0, len(log_lines), batch_size)):
        batch_lines = log_lines[i:i+batch_size]
        inputs = tokenizer(batch_lines, return_tensors='pt', truncation=True, padding='max_length', max_length=128)
        for k in inputs:
            inputs[k] = inputs[k].to(device)
        with torch.no_grad():
            out = model(**inputs)
            probs = torch.sigmoid(out.logits)
            token_scores = -torch.log(1 - probs + 1e-9)
            seq_scores = token_scores.mean(dim=1).cpu().numpy()
            scores.extend(seq_scores)
    return scores

scores = compute_anomaly_score_batch(test_logs, batch_size=32)

# 8. Threshold optimization and metrics
normal_scores = [s for s, lbl in zip(scores, df_balanced['label']) if lbl == 'Normal']
threshold = np.percentile(normal_scores, 95)
electra_preds = [1 if s <= threshold else 0 for s in scores]

print("\n--- ELECTRA Classification Report (95th percentile) ---")
print(classification_report(y_true, electra_preds, target_names=['Anomalous','Normal']))

# Best-F1 threshold optimization
prec, rec, thres = precision_recall_curve(y_true, [-s for s in scores])
f1s = 2 * prec * rec / (prec + rec + 1e-9)
best_idx = f1s.argmax()
best_threshold = thres[best_idx]
print(f"\nBest F1: {f1s[best_idx]:.2f} at threshold {best_threshold:.4f}")

electra_preds_best = [1 if s <= -best_threshold else 0 for s in scores]
print("\n--- ELECTRA Classification Report (Best F1 threshold) ---")
print(classification_report(y_true, electra_preds_best, target_names=['Anomalous','Normal']))

# ROC and PR Curve Plotting
fpr, tpr, roc_thresh = roc_curve(y_true, [-s for s in scores])
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc:.2f}')
plt.plot([0,1],[0,1],'--',c='gray')
plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ELECTRA ROC Curve')
plt.legend()
plt.grid(True)

plt.subplot(1,2,2)
plt.plot(rec, prec)
plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('ELECTRA Precision-Recall')
plt.grid(True)
plt.tight_layout()
plt.show()

# Save ELECTRA model and tokenizer
model.save_pretrained("electra_finetuned")
tokenizer.save_pretrained("electra_finetuned")