# -*- coding: utf-8 -*-
"""Week 7.1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkj2Npoy5fRTQd5tL3c6ehAru9u9YQ1N

#####ADVERSARIAL TRAINING
"""

# ─── Cell 1: Install & Imports ───────────────────────────────────────────────
!pip install pandas numpy scikit-learn sentence-transformers hmmlearn xmltodict

import os, pickle, re
import pandas as pd
import numpy as np

from sentence_transformers import SentenceTransformer
from sklearn.preprocessing      import MinMaxScaler
from sklearn.ensemble           import RandomForestClassifier
from sklearn.metrics            import confusion_matrix
from sklearn.model_selection    import train_test_split
from sklearn.metrics.pairwise   import cosine_similarity
from hmmlearn.hmm               import GaussianHMM

from google.colab import drive
drive.mount('/content/drive')

# ─── Cell 2: Reload models, preprocess logs & compute W_new ─────────────────
MODEL_DIR = '/content/drive/MyDrive/LLM4Sec/models'
# load saved objects
import pickle, os, numpy as np

with open(os.path.join(MODEL_DIR,'scaler_win.pkl'),'rb') as f:    scaler_win = pickle.load(f)
with open(os.path.join(MODEL_DIR,'nmf_model.pkl'),'rb')   as f:    nmf_model  = pickle.load(f)
with open(os.path.join(MODEL_DIR,'hmm_model.pkl'),'rb')   as f:    hmm_model  = pickle.load(f)

from sentence_transformers import SentenceTransformer
embedder = SentenceTransformer(os.path.join(MODEL_DIR,'sbert_model'))

# -------------------------------------------------
# Load & preprocess your new BGL log file
LOG_PATH = '/content/drive/MyDrive/LLM4Sec/Week8/BGL_log_test.csv'
logs = pd.read_csv(LOG_PATH, low_memory=False)

# cleaning helpers
def clean_text(s):
    return "" if pd.isna(s) else re.sub(r"\s+"," ",s.lower()).strip()
def apply_rules(cmd):
    return "" if pd.isna(cmd) else re.sub(r"\b\d+\b","num", cmd.lower())

logs['clean_msg'] = logs['Message'].apply(clean_text)
logs['proc_msg']  = logs['clean_msg'].apply(apply_rules)
parts = [c for c in ['System','Facility','Severity'] if c in logs.columns]
logs['Event']    = logs[parts].astype(str).agg(' :: '.join, axis=1) + ' :: ' + logs['proc_msg']

# -------------------------------------------------
# Build windows
def make_windows(df, L=10):
    ev, out = df['Event'].tolist(), []
    for i in range(0, len(ev), L):
        chunk = ev[i:i+L]
        if len(chunk)==L: out.append(" ||| ".join(chunk))
    return pd.DataFrame({'Window':out})

windows = make_windows(logs, L=10)

# -------------------------------------------------
# Embed → scale → clip → NMF
raw_emb = embedder.encode(windows['Window'].tolist(), show_progress_bar=True)
scaled  = scaler_win.transform(raw_emb)
# ensure non-negativity
scaled  = np.clip(scaled, 0.0, None)

W_new   = nmf_model.transform(scaled)
windows['cluster'] = hmm_model.predict(W_new)

print("Computed W_new with shape:", W_new.shape)

# ─── Cell 3: Adversarial Sample Generation & Concept Vectors ────────────────
# 1) Simple adversarial perturbation function
def adversarial_perturb(text):
    toks = text.split()
    if len(toks) > 2:
        idx = np.random.randint(len(toks))
        toks.pop(idx)
    return " ".join(toks)

# 2) Generate adversarial window texts
adv_windows = windows['Window'].apply(adversarial_perturb).tolist()

# 3) Embed adversarial windows
adv_emb    = embedder.encode(adv_windows, show_progress_bar=True)

# 4) Scale & clip to ≥0
adv_scaled = scaler_win.transform(adv_emb)
adv_scaled = np.clip(adv_scaled, 0.0, None)

# 5) Transform into NMF concept space
W_adv = nmf_model.transform(adv_scaled)

print("Adversarial concept matrix shape:", W_adv.shape)

# ─── Cell 4: Prepare & Train Robust Classifier ──────────────────────────────
# label 0 = clean, 1 = adversarial
X = np.vstack([W_new, W_adv])
y = np.hstack([np.zeros(len(W_new)), np.ones(len(W_adv))])

X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3,random_state=42)

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)
print("Val accuracy:", clf.score(X_val,y_val))

# ─── Cell 5: Re-evaluate on original clusters (DQ/DE) ────────────────────────
# map original windows as “attack” if in suspicious cluster
top_cluster = windows['cluster'].value_counts().idxmax()  # or pick from previous
y_true = (windows['cluster']==top_cluster).astype(int)

# get classifier’s prediction on clean windows
y_pred = clf.predict(W_new)

tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
accuracy    = (tp+tn)/(tp+tn+fp+fn)
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
fpr         = fp/(fp+tn)
fnr         = fn/(fn+tp)
dq = (accuracy + sensitivity + specificity)/3
de = (fpr + fnr)/2

print(f"DQ: {dq:.3f}, DE: {de:.3f}")

# ─── Cell 6: Save updated ensemble model ─────────────────────────────────────
OUT_DIR = '/content/drive/MyDrive/LLM4Sec/models'
with open(os.path.join(OUT_DIR,'adv_rf_clf.pkl'),'wb') as f:
    pickle.dump(clf, f)
print("Adversarial ensemble saved.")

# ─── Cell OPT1: Hyperparameter Tuning ────────────────────────────────────────
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble        import RandomForestClassifier

# Prepare training data (assuming X_train, y_train defined earlier)
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth':    [None, 10, 20],
    'class_weight':['balanced', None]
}
grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    refit=True
)
grid.fit(X_train, y_train)

# Best estimator
clf_opt = grid.best_estimator_
print("Best RF params:", grid.best_params_)

# ─── Cell OPT2: Evaluation of Optimized Model ───────────────────────────────
import matplotlib.pyplot as plt
from sklearn.metrics import (
    accuracy_score, f1_score, confusion_matrix,
    ConfusionMatrixDisplay, roc_curve, auc
)

# Predict on validation set
y_val_pred = clf_opt.predict(X_val)
y_val_proba= clf_opt.predict_proba(X_val)[:,1]

# Accuracy & F1
acc = accuracy_score(y_val, y_val_pred)
f1  = f1_score(y_val, y_val_pred)
print(f"Validation Accuracy: {acc:.3f}")
print(f"Validation F1‐Score: {f1:.3f}")

# Confusion Matrix
cm = confusion_matrix(y_val, y_val_pred)
ConfusionMatrixDisplay(cm).plot(); plt.show()

# AUC‐ROC
fpr, tpr, _ = roc_curve(y_val, y_val_proba)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0,1],[0,1],'--'); plt.xlabel("FPR"); plt.ylabel("TPR")
plt.title("ROC Curve"); plt.legend(); plt.show()

# DQ & DE
tn, fp, fn, tp = cm.ravel()
accuracy    = (tp+tn)/(tp+tn+fp+fn)
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
fpr_rate    = fp/(fp+tn)
fnr_rate    = fn/(fn+tp)
DQ = (accuracy + sensitivity + specificity)/3
DE = (fpr_rate + fnr_rate)/2
print(f"Detection Quality (DQ): {DQ:.3f}")
print(f"Detection Error   (DE): {DE:.3f}")

# ─── Cell OPT3: Save Optimized Adversarial Ensemble ────────────────────────
import pickle, os

SAVE_DIR = '/content/drive/MyDrive/LLM4Sec/models'
os.makedirs(SAVE_DIR, exist_ok=True)

with open(os.path.join(SAVE_DIR, 'adv_rf_clf_opt.pkl'), 'wb') as f:
    pickle.dump(clf_opt, f)

print("Optimized adversarial RF saved to:", os.path.join(SAVE_DIR, 'adv_rf_clf_opt.pkl'))