# -*- coding: utf-8 -*-
"""Week 7.2(Classification).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PlaIkEk4HOwNoD1Pp4vGpX_xJg_uVieg
"""

# ─── Cell 1: Install dependencies & mount Google Drive ─────────────────────
!pip install pandas numpy scikit-learn sentence-transformers tensorflow

from google.colab import drive
drive.mount('/content/drive')

# ─── Cell 2: Imports ────────────────────────────────────────────────────────
import os, pickle, re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sentence_transformers import SentenceTransformer
from sklearn.ensemble        import RandomForestClassifier
from sklearn.metrics         import (
    accuracy_score, f1_score, confusion_matrix,
    ConfusionMatrixDisplay, roc_curve, auc
)
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras import layers, models

# ─── Cell 3: Reload RF‐Ensemble, SBERT & Prepare Test Windows ──────────────
MODEL_DIR = '/content/drive/MyDrive/LLM4Sec/models'
# Load optimized RF
with open(os.path.join(MODEL_DIR, 'adv_rf_clf_opt.pkl'), 'rb') as f:
    clf_opt = pickle.load(f)
# Load SBERT & scaler & NMF
embedder   = SentenceTransformer(os.path.join(MODEL_DIR, 'sbert_model'))
with open(os.path.join(MODEL_DIR, 'scaler_win.pkl'), 'rb') as f:
    scaler_win = pickle.load(f)
with open(os.path.join(MODEL_DIR, 'nmf_model.pkl'), 'rb') as f:
    nmf_model  = pickle.load(f)

# Load & label test logs
LOG_PATH = '/content/drive/MyDrive/LLM4Sec/Week8/BGL_log_test.csv'
logs = pd.read_csv(LOG_PATH, low_memory=False)
logs['Label'] = logs['Alert_Tag'].apply(lambda x: 0 if str(x).strip()=='-' else 1)

# Text cleaning & masking functions
def clean_text(s):
    return "" if pd.isna(s) else re.sub(r"\s+"," ",str(s).lower()).strip()
def mask_nums(s):
    return "" if pd.isna(s) else re.sub(r"\b\d+\b","num",str(s).lower())

logs['clean_msg'] = logs['Message'].apply(clean_text)
logs['proc_msg']  = logs['clean_msg'].apply(mask_nums)

# Build Event strings
parts = [c for c in ['System','Facility','Severity'] if c in logs.columns]
logs['Event'] = logs[parts].astype(str).agg(' :: '.join, axis=1) + ' :: ' + logs['proc_msg']

# Windowing
def make_windows(df, L=10):
    ev = df['Event'].tolist()
    lbl= df['Label'].tolist()
    wins, win_lbl = [], []
    for i in range(0, len(ev), L):
        chunk_ev  = ev[i:i+L]
        chunk_lbl = lbl[i:i+L]
        if len(chunk_ev)==L:
            wins.append(" ||| ".join(chunk_ev))
            win_lbl.append(int(max(chunk_lbl)))
    return pd.DataFrame({'Window': wins, 'Label': win_lbl})

windows = make_windows(logs, L=10)

# Embed windows → scale → clip → NMF
raw_emb = embedder.encode(windows['Window'].tolist(), show_progress_bar=True)
scaled  = scaler_win.transform(raw_emb)
scaled  = np.clip(scaled, 0.0, None)
W_new   = nmf_model.transform(scaled)

# True labels
y_true = windows['Label'].values

# ─── Cell 4: Evaluate RF‐Ensemble only ───────────────────────────────────────
# Predictions
y_pred_rf  = clf_opt.predict(W_new)
y_proba_rf = clf_opt.predict_proba(W_new)[:,1]

# Evaluation
def eval_metrics(y_true, y_pred, y_proba=None, title="Model"):
    acc = accuracy_score(y_true, y_pred)
    f1  = f1_score(y_true, y_pred)
    print(f"{title} → Acc: {acc:.3f}, F1: {f1:.3f}")
    cm = confusion_matrix(y_true, y_pred)
    ConfusionMatrixDisplay(cm).plot(cmap='Blues')
    plt.title(f"{title} Confusion Matrix")
    plt.show()
    if y_proba is not None:
        fpr, tpr, _ = roc_curve(y_true, y_proba)
        print(f"{title} AUC: {auc(fpr,tpr):.3f}")
        plt.plot(fpr, tpr, label=f"AUC={auc(fpr,tpr):.3f}")
        plt.plot([0,1],[0,1],'--', color='gray')
        plt.title(f"{title} ROC Curve")
        plt.xlabel("FPR"); plt.ylabel("TPR"); plt.legend(); plt.show()
    tn,fp,fn,tp = cm.ravel()
    sens = tp/(tp+fn) if (tp+fn)>0 else 0
    spec = tn/(tn+fp) if (tn+fp)>0 else 0
    dq = (acc + sens + spec)/3
    de = ((fp/(fp+tn) if (fp+tn)>0 else 0) + (fn/(fn+tp) if (fn+tp)>0 else 0))/2
    print(f"{title} DQ: {dq:.3f}, DE: {de:.3f}\n")

eval_metrics(y_true, y_pred_rf, y_proba_rf, title="RF-Ensemble")

# ─── Cell 4.5: Build sequence arrays & train/test split ─────
#    windows['Window'] contains strings of 10 events joined by " ||| "
event_seqs  = [w.split(" ||| ") for w in windows['Window'].tolist()]
flat_events = [evt for seq in event_seqs for evt in seq]

# 2) Embed all events with SBERT
embeddings  = embedder.encode(flat_events, show_progress_bar=True)  # shape (n_windows*10, EMB_DIM)

# 3) Reshape into (n_windows, 10, EMB_DIM)
n_windows = len(event_seqs)
SEQ_LEN   = len(event_seqs[0])
EMB_DIM   = embeddings.shape[1]
X_seq     = embeddings.reshape(n_windows, SEQ_LEN, EMB_DIM)

# 4) Labels per window
y_seq = windows['Label'].values  # shape (n_windows,)

print(f"X_seq shape: {X_seq.shape}   y_seq shape: {y_seq.shape}")

# 5) Train/test split
from sklearn.model_selection import train_test_split
X_tr, X_te, y_tr, y_te = train_test_split(
    X_seq, y_seq,
    test_size=0.3,
    stratify=y_seq,
    random_state=42
)
print("Train shape:", X_tr.shape, y_tr.shape, "Test shape:", X_te.shape, y_te.shape)

# ─── Cell 5: Pure‐TF GRU (CPU only) over Event-Sequence Embeddings ─────────
import os
# Turn off GPU so we never hit CuDNN
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import (
    accuracy_score, f1_score, roc_curve, auc,
    confusion_matrix, ConfusionMatrixDisplay
)
import matplotlib.pyplot as plt

# Assume X_seq, y_seq, SEQ_LEN, EMB_DIM already defined, and train/test split done
# X_tr, X_te, y_tr, y_te

# Build the model
tf.keras.backend.clear_session()
with tf.device('/CPU:0'): # Explicitly set device to CPU
    model_gru = models.Sequential([
        layers.Input(shape=(SEQ_LEN, EMB_DIM)),
        layers.Masking(),
        # Use recurrent_dropout to force non-CuDNN kernel
        layers.GRU(128, recurrent_dropout=1e-8),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')
    ])
model_gru.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
model_gru.summary()

# Train
history = model_gru.fit(
    X_tr, y_tr,
    validation_split=0.1,
    epochs=5,
    batch_size=32
)

# Evaluate
y_prob = model_gru.predict(X_te).ravel()
y_pred = (y_prob > 0.5).astype(int)

acc = accuracy_score(y_te, y_pred)
f1  = f1_score(y_te, y_pred)
print(f"GRU (pure‐TF) Accuracy: {acc:.3f}, F1‐Score: {f1:.3f}")

# Confusion matrix
cm = confusion_matrix(y_te, y_pred)
ConfusionMatrixDisplay(cm).plot(cmap='Blues')
plt.title("GRU Confusion Matrix"); plt.show()

# ROC
fpr, tpr, _ = roc_curve(y_te, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f"AUC={roc_auc:.3f}")
plt.plot([0,1],[0,1],'--', color='gray')
plt.title("GRU ROC Curve"); plt.xlabel("FPR"); plt.ylabel("TPR"); plt.legend(); plt.show()

# DQ/DE
tn,fp,fn,tp = cm.ravel()
sens = tp/(tp+fn) if (tp+fn)>0 else 0
spec = tn/(tn+fp) if (tn+fp)>0 else 0
DQ   = (acc + sens + spec)/3
DE   = ((fp/(fp+tn) if (fp+tn)>0 else 0) + (fn/(tp+fn) if (tp+fn)>0 else 0)) / 2
print(f"GRU Detection Quality: {DQ:.3f}, Detection Error: {DE:.3f}")

# ─── Cell 6a: Save as Keras v3 native format ──────────────────────────────
SAVE_PATH = '/content/drive/MyDrive/LLM4Sec/models/gru_anomaly_model.keras'
model_gru.save(SAVE_PATH)
print("Saved GRU (Keras format) to", SAVE_PATH)

# After model_gru.fit(...) returned `history`
import matplotlib.pyplot as plt

# Loss
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title("Training vs. Validation Loss")
plt.xlabel("Epoch"); plt.ylabel("Binary Crossentropy")
plt.legend(); plt.show()

# Accuracy
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.title("Training vs. Validation Accuracy")
plt.xlabel("Epoch"); plt.ylabel("Accuracy")
plt.legend(); plt.show()

#Using Stronger regularization
from tensorflow.keras import regularizers

layers.GRU(128,
          kernel_regularizer=regularizers.l2(1e-4),
          recurrent_regularizer=regularizers.l2(1e-4),
          dropout=0.2, recurrent_dropout=0.2)

# ─── Cell X: Classification Report for the Loaded GRU Model ────────────────
from sklearn.metrics import classification_report

# 1) Get predicted probabilities and binary predictions
y_prob_gru = model_gru.predict(X_te).ravel()
y_pred_gru = (y_prob_gru > 0.5).astype(int)

# 2) Print sklearn’s classification report
print(classification_report(
    y_te,
    y_pred_gru,
    target_names=['Benign (0)','Anomalous (1)'],
    digits=4
))

# ─── Cell 6: Re-build + Train with Regularization & EarlyStopping ─────────
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# 6.1) Clear & rebuild with L2 + dropout
tf.keras.backend.clear_session()
model_gru = models.Sequential([
    layers.Input(shape=(SEQ_LEN, EMB_DIM)),
    layers.Masking(),
    layers.GRU(
        128,
        activation='tanh',
        recurrent_activation='sigmoid',
        kernel_regularizer=regularizers.l2(1e-4),
        recurrent_regularizer=regularizers.l2(1e-4),
        dropout=0.2,
        recurrent_dropout=0.2
    ),
    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])
model_gru.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
model_gru.summary()

# 6.2) Early stopping on val_loss
es = EarlyStopping(
    monitor='val_loss',
    patience=2,
    restore_best_weights=True
)

# 6.3) Fit on your training split
history = model_gru.fit(
    X_tr, y_tr,
    validation_split=0.1,
    epochs=15,        # can raise this safely with early stopping
    batch_size=32,
    callbacks=[es]
)

# 6.4) Plot train vs val curves
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['loss'],  label='train loss')
plt.plot(history.history['val_loss'],label='val loss')
plt.title("Loss"); plt.xlabel("Epoch"); plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'],     label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.title("Accuracy"); plt.xlabel("Epoch"); plt.legend()
plt.show()

# 6.5) Evaluate on hold-out test set
y_prob = model_gru.predict(X_te).ravel()
y_pred = (y_prob > 0.5).astype(int)

# 6.6) Classification report
print(classification_report(
    y_te,
    y_pred,
    target_names=['Benign (0)', 'Anomalous (1)'],
    digits=4
))